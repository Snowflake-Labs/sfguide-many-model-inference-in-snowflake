{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764f9069-1d68-428d-adfd-47939ee2ac1e",
   "metadata": {
    "collapsed": false,
    "name": "OVERVIEW",
    "resultHeight": 221
   },
   "source": [
    "## Many Model Inference in Snowflake\n",
    "\n",
    "This notebook accompanies the [Many Model Inference in Snowflake](https://quickstarts.snowflake.com/guide/many-model-inference-in-snowflake/index.html?index=..%2F..index#0) quickstart. In the notebook, we will show how you can use pretrained models to define a [partitioned custom model](https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/partitioned-custom-models) in Snowflake. The model will run inference using a model based on the value in the partition column -- in our case the Station ID. \n",
    "\n",
    "We will start with imports and defining the session and constants. Please add `snowflake-ml-python` and `cloudpickle==2.2.1` from the packages dropdown before starting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "get_snowflake_session",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.ml.model import custom_model\n",
    "from snowflake.ml.registry import registry\n",
    "\n",
    "from typing import Optional\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "# Add a query tag to the session.This helps with performance monitoring and troubleshooting\n",
    "session.query_tag = {\"origin\":\"sf_sit-is\", \n",
    "                     \"name\":\"partitioned_models_stateful\", \n",
    "                     \"version\":{\"major\":1, \"minor\":0},\n",
    "                     \"attributes\":{\"is_quickstart\":1, \"source\":\"notebook\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21853959-8c65-4199-aa10-00c8f8777fea",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "set_constants",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "DATABASE = session.get_current_database()\n",
    "SCHEMA = session.get_current_schema()\n",
    "\n",
    "_INPUT_COLS = ['PASSENGER_COUNT', 'TRIP_DISTANCE', 'FARE_AMOUNT', \n",
    "               'PAYMENT_TYPE_1', 'PAYMENT_TYPE_2', 'PAYMENT_TYPE_3',\n",
    "               'PAYMENT_TYPE_4', 'PAYMENT_TYPE_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d629a97-a9ad-480f-ad00-e003f4213f35",
   "metadata": {
    "collapsed": false,
    "name": "DEFINE_MODEL",
    "resultHeight": 165
   },
   "source": [
    "### Define the Partitioned Model\n",
    "\n",
    "We will now define the custom model. The partitoned custom model class inherits from `snowflake.ml.model.custom_model.CustomModel`, and inference methods are declared with the `@custom_model.partitioned_inference_api` decorator. Writing the model in this way allows it to run in parallel for each partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d3972-70dd-4533-b57a-fca016b9fff7",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "define_partitioned_model",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class TaxiForecastingModelPickleInput(custom_model.CustomModel):\n",
    "    def __init__(self, context: Optional[custom_model.ModelContext] = None) -> None:\n",
    "        super().__init__(context)\n",
    "        self.partition_id = None\n",
    "        self.model = None\n",
    "\n",
    "    @custom_model.partitioned_inference_api\n",
    "    def predict(self, input: pd.DataFrame) -> pd.DataFrame:\n",
    "        input_cols = _INPUT_COLS\n",
    "\n",
    "        if self.partition_id != input['PULOCATIONID'][0]:\n",
    "            self.partition_id = input['PULOCATIONID'][0]\n",
    "            self.model = pickle.loads(input['MODEL_PICKLE_BYTES'][0])\n",
    "\n",
    "        model_output = self.model.predict(input[input_cols])\n",
    "        res = pd.DataFrame(model_output, columns=[\"TOTAL_AMOUNT\"])\n",
    "        res['PULOCATIONID_OUT'] = input['PULOCATIONID']\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0aae6-0a1f-4ea0-be9f-84ebf1a9934c",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "create_model_instance",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "m = TaxiForecastingModelPickleInput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa2aa7-d5b8-45d8-911b-89a120f90037",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "show_model_instance",
    "resultHeight": 371
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d2a86-ab6a-4f05-a176-88baf5b8de50",
   "metadata": {
    "collapsed": false,
    "name": "LOG_MODEL",
    "resultHeight": 113
   },
   "source": [
    "### Log Model to Model Registry\n",
    "\n",
    "Next we will log the model to Snowflake Model Registry. We will first define the signature for our prediction method, then define the registry, and finally log the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c91345f-228d-46ce-94d6-4df0e964b967",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "define_signature",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.model.model_signature import FeatureSpec, DataType, ModelSignature\n",
    "\n",
    "input_signature= [\n",
    "  FeatureSpec(dtype=DataType.INT64, name='PULOCATIONID', nullable=True),\n",
    "  FeatureSpec(dtype=DataType.INT64, name='PASSENGER_COUNT', nullable=True),\n",
    "  FeatureSpec(dtype=DataType.DOUBLE, name='TRIP_DISTANCE', nullable=True),\n",
    "  FeatureSpec(dtype=DataType.DOUBLE, name='FARE_AMOUNT', nullable=True),\n",
    "  FeatureSpec(dtype=DataType.BOOL, name='PAYMENT_TYPE_1', nullable=True),\n",
    "  FeatureSpec(dtype=DataType.BOOL, name='PAYMENT_TYPE_2', nullable=True),\n",
    "  FeatureSpec(dtype=DataType.BOOL, name='PAYMENT_TYPE_3', nullable=True),\n",
    "  FeatureSpec(dtype=DataType.BOOL, name='PAYMENT_TYPE_4', nullable=True),\n",
    "  FeatureSpec(dtype=DataType.BOOL, name='PAYMENT_TYPE_5', nullable=True),\n",
    "  FeatureSpec(dtype=DataType.BYTES, name='MODEL_PICKLE_BYTES', nullable=True),\n",
    "]\n",
    "\n",
    "output_signature = [\n",
    "    FeatureSpec(dtype=DataType.FLOAT, name='TOTAL_AMOUNT'),\n",
    "    FeatureSpec(dtype=DataType.STRING, name='PULOCATIONID_OUT'),\n",
    "]\n",
    "\n",
    "signature = ModelSignature(\n",
    "    inputs=input_signature,\n",
    "    outputs=output_signature,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef97b6-9f0c-439b-ab4d-bf501e1f2b90",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "define_registry",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Log model\n",
    "reg = registry.Registry(session=session, \n",
    "                        database_name=DATABASE, \n",
    "                        schema_name=SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e81611-d161-4d4c-91f5-5638d369fdf5",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "show_existing_models",
    "resultHeight": 182
   },
   "outputs": [],
   "source": [
    "reg.show_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d516990e-db0f-4234-930a-29c997378814",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "log_model",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"function_type\": \"TABLE_FUNCTION\",\n",
    "    \"relax_version\": False\n",
    "}\n",
    "\n",
    "mv = reg.log_model(\n",
    "    m,\n",
    "    model_name=\"taxi_total_amount_forecast_model\",\n",
    "    version_name=\"v1\",\n",
    "    options=options,\n",
    "    conda_dependencies=[\"pandas\", \"xgboost\", \"cloudpickle==2.2.1\"], # cloudpickle version should be greater than 2.0.0 in notebook as well\n",
    "    signatures={\"predict\": signature}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4edbb-abdf-4e16-8c06-b3ac7d28c15e",
   "metadata": {
    "collapsed": false,
    "name": "INFERENCE",
    "resultHeight": 113
   },
   "source": [
    "### Run Inference\n",
    "\n",
    "Finally, we will run inference using our custom partitioned model. We will pull the input data we defined in the setup notebook, then run inference, and save the results to a table in Snowflake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd3ba04-0515-44b2-a8a8-e4d8ca9562d5",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "create_input_df",
    "resultHeight": 351
   },
   "outputs": [],
   "source": [
    "input_df = session.table(f\"{DATABASE}.{SCHEMA}.INPUT_DATA\")\n",
    "\n",
    "model_bytes_table = session.table(f\"{DATABASE}.{SCHEMA}.MODELS_TABLE\")\n",
    "input_df = input_df.join(model_bytes_table, on=\"PULOCATIONID\", type=\"left\")\n",
    "input_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4469db-cf4c-465a-b682-52089e8dd3ab",
   "metadata": {
    "collapsed": false,
    "name": "inference_md",
    "resultHeight": 118
   },
   "source": [
    "Let's see how many distinct stations there are in the test data. Each station corresponds to a different model in the logged partitioned model. When we run inference, each station will run with the relevant model in parallel, speeding up inference and ensuring accurate results with a model trained only on relevant station data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d539f-6290-4112-b0b6-02c096d844d7",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "partition_count",
    "resultHeight": 58
   },
   "outputs": [],
   "source": [
    "input_df.select(\"PULOCATIONID\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e330c12f",
   "metadata": {
    "collapsed": false,
    "name": "inference_2_md",
    "resultHeight": 118
   },
   "source": [
    "We will now run inference for the entire input dataframe. Because we built the model as partitioned, we will split the data into partitions based on pick up location and run inference with the relevant model that we pulled from the models table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844dbac9-b9f4-40ab-a53c-2ceba7fb324b",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "run_inference",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "result = mv.run(input_df, partition_column=\"PULOCATIONID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9ccd7b",
   "metadata": {
    "collapsed": false,
    "name": "inference_3_md",
    "resultHeight": 118
   },
   "source": [
    "Finally, we will save the results to a table and view them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc6f40-60c6-486e-97c7-a870fd8ea026",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "save_results",
    "resultHeight": 1143
   },
   "outputs": [],
   "source": [
    "result.write.mode(\"overwrite\").save_as_table(\"RESULTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1487ae0-5673-4594-87b9-fd7b9e7003f4",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "view_results",
    "resultHeight": 335
   },
   "outputs": [],
   "source": [
    "result_df = session.table(\"RESULTS\")\n",
    "result_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
